\chapter{Re-implementing de Boer (2000)}
\label{ch:reimplementing}
% beter gebruik classes en doc
% formules van ons vergelijken met die van de boer want soms anders in paper en code
% cleaner afgaan van mogelijke shift
% semi random add ipv random zoals gezegd
% equal van vowels beter bespreken

The original C++ source code of \citet{deBoer2000} was provided to us, de Boer's students.
However, this code was dated and not meant for distribution, which made it difficult to be used or extended upon.
Because we saw the value in a well documented and easy to extend implementation of this project, we decided to fully re-implement it in Python.
This was done incrementally, with each step described in \texttt{1\_implementing\_de\_boer\_2000.ipynb}.
The working of the code was validated by reproducing the results of the experiments by \citet{deBoer2000} in \texttt{2\_recreating\_de\_boer\_2000.ipynb}.
This chapter will summarise the development and findings of these two Jupyter notebooks.
We stress that all of the discussed code in what follows is either derived from textual description in \citet{deBoer2000} or the provided C++ code.

%------------------------------------

\section{Producing sounds}
\label{sec:reimplementing_producing}

\citet{deBoer2000} system consists of agents who can produce, perceive, and remember speech sounds in a human-like way.
The most important component for producing sounds in a human-like manner is the articulatory synthesizer.
This synthesizer takes as input three vowel parameters: the tongue position ($p$), the tongue height ($h$) and the lip rounding ($r$).
The outputs of the synthesizer are the first four formant frequencies of the corresponding vowel: $F_1$ to $F_4$ expressed in $Hz$.
The conversion between input and output happens based on the synthesizer equations given by \citet{deBoer2000}, table 2.
\Citet{deBoer2000} used interpolation from known data to create these equations.
We used these known points for validating our $F_1$ to $F_4$ conversions from the $p$, $h$ and $r$ input and found them to match perfectly with the given data.

From the above-described synthesizer equations, we can make the \texttt{Synthesizer} class.
To represent input and output formally, we make use of two helper classes: \texttt{Utterance} and \texttt{Phoneme}.
The former stores an utterance consisting of the four formants $F_1$ to $F_4$.
This is the output of the \texttt{synthesise} function.
A phoneme is used as input for the same function and stores the $p$, $h$ and $r$ parameters.
Two types of noise can be assigned to a \texttt{Synthesizer} object.
The \texttt{max\_noise\_agent} and the \texttt{max\_noise\_ambient}.
The agent noise is applied to the phoneme before utterance creation (Equation \ref{eq:reimplementing_noise_agent}), the ambient noise is applied to the utterance after creation.
The applied noise, $\lambda$, is uniformly picked from: $\frac{-\psi}{2} \leq \lambda \leq \frac{\psi}{2}$, with $\psi$ being the provided parameter.
$\psi$ is one of many important parameters.
In the experiments by \citet{deBoer2000}, only the ambient noise is used.

\begin{equation}
F^{agent}_{i}(p, h, r) = F_{i}(p + \lambda, h + \lambda, r + \lambda)
\label{eq:reimplementing_noise_agent}
\end{equation}

\begin{equation}
F^{ambient}_{i} = F_{i} * (1 + \lambda)
\label{eq:reimplementing_noise_ambient}
\end{equation}

%------------------------------------
\section{Perceiving sounds}
\label{sec:reimplementing_perceive}

With the \texttt{Synthesizer} and helper classes in place, an agent can produce a signal that represents sound in a human-like manner.
For an agent to perceive these signals in a human-like manner, the \texttt{Bark Operator} class is created.
This class is responsible for working with utterances.
Remember that utterances were the first four formants of a generated sound, in Hertz.
As the name of this class implies, the Bark scale is used by this class and is differing from the previously used Hertz scale. 
It represents frequencies in a manner that is closer to human perception.
It goes from the four formant representation in Hertz to a two formant representation in Bark consisting of the first formant and the \textit{effective second-formant} ($F'_2$).

We took the conversion formulae and calculation formula for the effective second formant straight from \citet{deBoer2000}.
The conversion from Hertz to Bark and back used by \citet{deBoer2000} is again interpolated from data.
It is also admitted by \citet{deBoer2000} that his calculations for determining ($F'_2$) are a bit ad hoc.
The critical distance used for calculating ($F'_2$) can be provided as an optional argument.
Because of the interpolated conversion and ad hoc ($F'_2$) calculations, we have also foreseen an \texttt{alternative\_bark\_conversion} parameter.
If set to \texttt{True}, the Bark operator will use alternative methods for both of these functions.
This is further discussed in section \ref{sec:reimplementing_better}.

Having our Bark space configured, we can implement a distance measure between utterances as specified in Equation \ref{eq:reimplementing_distance}.
This distance measure can be used as a way for the agent to determine the closest sound in his repertoire to the one it heard.
This must happen in the Bark space as equal distances in bark correspond to roughly equal human-perceptual distances of sound.
This is not the case for Hertz, as humans have a harder time differentiating higher frequencies.
With this human-like distance measure, agents can now perceive sounds and compare them with their known sounds.
This $\lambda$ is again an important parameter for the simulations.
It is set to $0.3$ for all experiments in the project unless specified differently.
This value is seen as realistic by \citet{Schwartz1997, deBoer2000, vallee1994, 1985book}.

\begin{equation}
D = \sqrt{ ( F^a_1 - F^b_1 ) ^2 + \lambda ( F'^a_2 - F'^b_2 )^2 }
\label{eq:reimplementing_distance}
\end{equation}

%------------------------------------
\section{Representing agents}
\label{sec:reimplementing_agents}

The \texttt{Agent} class makes use of all previously discussed classes as well as the \texttt{Sound} helper class.
The \texttt{Agent} class takes a synthesizer and Bark operator as arguments for initialising.
It also has over ten optional parameters one of which is a logging capability handy for debugging purposes.
The \texttt{Sound} class is used to store a known sound of an agent.
It consists of the phoneme, utterance, usage count and success count of the sound.
The utterance of this sound is determined by synthesising the provided phoneme in a noiseless environment.

To discuss the functions of an agent, it is easiest to present a typical imitation game flow.
Algorithm \ref{alg:say_something} shows the actions performed by a randomly picked agent who starts an imitation game.
If the agent known sound repertoire is empty a completely random vowel is inserted by picking random values between $0$ and $1$ for the Phoneme parameters.
A different randomly picked agent plays the role of imitator and response to the heard utterance using the process shown in Algorithm \ref{alg:imitate_sound}.
If the imitator's known sounds repertoire is empty, it will add a \textit{similar sound} to the one it heard.
It does this by checking eight \textit{corner} sounds it can produce and picking the one which is closest in distance.
Afterwards it improves this sound further by using its \texttt{improve\_sound} function for the agent specific amount of times (\texttt{max\_similar\_sound\_loops} parameter).
The \texttt{improve\_sound} function tries all possible permutation's of the phoneme parameters by either keeping the value or adding/substracting the agent specific step size (\texttt{phoneme\_step\_size} parameter).

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The say\_something function of an imitation game initiator agent}\label{alg:say_something}
\begin{algorithmic}
\If{No known sounds}
    \State Add random sound to known sounds
\EndIf

\State $S \gets$ random known sound
\State Update usage count of $S$
\State Remember chose of $S$
\State Return utterance of $S$ using own bark operator


\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The imitate\_sound function of an imitator}\label{alg:imitate_sound}
\begin{algorithmic}
\Require $U_{in}$: the heard utterance
\If{No known sounds}
    \State Add similar sound for $U_{in}$ to known sounds
\EndIf

\State Remember $U_{in}$
\State Find closest known sounds $S$ to heard utterance
\State Update usage count of $S$
\State Remember chose of $S$
\State Return utterance of $S$ using own bark operator


\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

In the second phase of the game, the initiator validates the imitation it hears in a non-verbal manner.
This process is shown in Algorithm \ref{alg:validate_imitation}.
The agent validates if the closest known sound to the heard imitation utterance is the sound he used to start the game.
He also communicates this to the imitating agent in a non-verbal manner.
He updates the success count accordingly and prepares himself for the next round.
The process of preparing for a new round is given in Algorithm \ref{alg:prepare_new}.
This consists of resetting the game variables such as the $last\_spoken\_sound$ variable.
The agent then updates its count of games played, ads well as the success and imitator/initiator count respectively.
Based on the agent specific \texttt{cleanup\_prob}, \texttt{new\_sound\_prob} and \texttt{merge\_prob} the agent will potentially remove bad sounds, add a semi-random new sound or merge similar sounds.
A sound is thus removed periodically if it's success rate is below the agent specific \texttt{sound\_threshold\_agent} and used at least \texttt{sound\_minimum\_tries}, which is also agent specific.
A sound is also added semi-randomly on a periodic basis.
We call this process semi-random as multiple random vowels will be tried based on the agent specific \texttt{max\_semi\_random\_loop}, and the sound that had the greatest summed distance will be used as new sound.
Finally, similar sounds are also merged on a periodic basis.
The agent does this by validating if both the utterance or phonemes don't lie too close.
Phonemes lie too close if their parameters differ less then 0.17 in total.
Utterance are too close if they can't be distinguished taking into account the noise of the environment.
Both of these calculations are taken from the code provided by \citet{deBoer2000}.


%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The validate\_imitation function of an initiator}\label{alg:validate_imitation}
\begin{algorithmic}
\Require $U_{in}$: the heard imitation utterance

\State Retrieve last spoken sound $S$
\State Find closest known sounds $S'$ to heard utterance
\State $success \gets$ $S = S'$ ?
\If{$success$}
    \State Update success count of $S$
\EndIf

\State Prepare for new game
\State Return $success$
\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The prepare\_for\_new\_game function of an agent}\label{alg:prepare_new}
\begin{algorithmic}
\Require $imitator$: whether or not the agent was an imitator in the played game
\Require $success$: whether or not the played game was a success

\State Update agent games count
\If{$success$}
    \State Update agent success count
\EndIf

\If{$imitator$}
    \State Update agent imitator count
\Else
    \State Update agent initiator count
\EndIf

\State Remove bad sounds per agent specific odd
\State Merge similar sounds per agent specific odd
\State Add semi-random sound per agent specific odd

\State Reset game variables

\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------
\newpage
To end a game cycle, the imitator agent will process the non-verbal imitation success communication.
It does using the process described in Algorithm \ref{alg:non_verbal}.
If the imitation was successful the agent will use the previously described \texttt{improve\_sound} function once to make the spoken sound better match the heard utterance.
If the imitation was not successful and the used sound has a success ratio lower then the agent specific \texttt{sound\_threshold\_game}, the sound is also improved as described before.
However, if the success ratio of the sound is above this threshold it is assumed that the spoken sound is a correct imitation of other sounds in the network and thus a similar sound is added to the one heard as reaction.
The process of adding this similar sound is identical as described when the sound repertoire of an imitator was empty.


\begin{algorithm}[hbt!]
\caption{The process\_non\_verbal\_imitation\_confirmation function of an imitator}\label{alg:non_verbal}
\begin{algorithmic}
\Require $success$: whether or not the imitation was a success


\State Update agent games count
\If{$success$}
    \State Update agent success count
    \State Improve used sound to better match heard utterance
\ElsIf{Low success ratio of spoken sound}
    \State Improve used sound to better match heard utterance
\Else
    \State Add a similar sound to the heard utterance
\EndIf

\State Remove bad sounds per agent specific odd
\State Merge similar sounds per agent specific odd
\State Add semi-random sound per agent specific odd

\State Reset game variables

\end{algorithmic}
\end{algorithm}

%------------------------------------
\section{Playing and analysing games}
\label{sec:reimplementing_game_engine}
% Game engine en Game State kort beschrijven 
TODO

%------------------------------------

\section{Improving de Boer (2000)}
\label{sec:reimplementing_better}
% BV die dingen dat ad-hoc waren en jij beter gemaakt hebt 
% andere bark gebruikt (conversion en effective second formant)
% Mss betere weighting factors bezien
TODO