\chapter{Re-implementing de Boer (2000)}
\label{ch:reimplementing}

The original C++ source code of \citet{deBoer2000} was provided to us, de Boer's students.
However, this code was dated and not meant for distribution, which made it difficult to be used or extended upon.
Because we saw the value in a well documented and easy to extend implementation of this project, we decided to fully re-implement it in Python.
This was done incrementally, with each step described in \texttt{1\_implementing\_de\_boer\_2000.ipynb}.
The working of the code was validated by reproducing the results of the experiments by \citet{deBoer2000} in \texttt{2\_recreating\_de\_boer\_2000.ipynb}.
This chapter will summarise the development and findings of these two Jupyter notebooks.
We stress that all of the discussed code in what follows is either derived from the textual description in \citet{deBoer2000} or the provided C++ code.

%------------------------------------

\section{Producing sounds}
\label{sec:reimplementing_producing}

The ABM of \citet{deBoer2000} consists of agents who can produce, perceive, and remember speech sounds in a human-like way.
The most important component for producing sounds in a human-like manner is the articulatory synthesizer.
This synthesizer takes as input three parameters related to the vocal tract configuration: the tongue position ($p$), the tongue height ($h$) and the lip rounding ($r$).
These input parameters are represented using a \texttt{Phoneme} class object.
The outputs of the synthesizer are the first four formant frequencies of the corresponding vowel: $F_1$ to $F_4$ expressed in $Hz$.
This output is represented as a \texttt{Utterance} class object.
The conversion between input and output happens based on equations given by \citet{deBoer2000}, table 2.
A small typo in the provided calculation for $F_3$ has been corrected in our code.
\Citet{deBoer2000} used interpolation from known data to create these equations.
We used these known points for validating our $F_1$ to $F_4$ conversions from the $p$, $h$ and $r$ input and found them to match perfectly with the given data.
It is noted that the interpolated approach of \citet{deBoer2000} makes the synthesising process faster than a full vocal synthesizer system but forms a clear simplification.

The above-discussed process is implemented in the \texttt{Synthesizer} class.
A synthesizer is initialised by providing two types of noise.
The \texttt{max\_noise\_agent} and the \texttt{max\_noise\_ambient}.
The agent noise is applied to the phoneme before utterance creation (Equation \ref{eq:reimplementing_noise_agent}), the ambient noise is applied to the utterance after creation.
The applied noise, $\lambda$, is uniformly picked from: $\frac{-\psi}{2} \leq \lambda \leq \frac{\psi}{2}$, with $\psi$ being the provided parameter.
$\psi$ is one of many important parameters.
In the experiments by \citet{deBoer2000}, only the ambient noise is used.

\begin{equation}
F^{agent}_{i}(p, h, r) = F_{i}(p + \lambda, h + \lambda, r + \lambda)
\label{eq:reimplementing_noise_agent}
\end{equation}

\begin{equation}
F^{ambient}_{i} = F_{i} * (1 + \lambda)
\label{eq:reimplementing_noise_ambient}
\end{equation}

%------------------------------------
\section{Perceiving sounds}
\label{sec:reimplementing_perceive}

With the \texttt{Synthesizer} and helper classes in place, an agent can produce a signal that represents sound in a human-like manner.
For an agent to perceive these signals in a human-like manner, the \texttt{Bark Operator} class is created.
This class is responsible for working with utterances.
Remember that utterances were the first four formants of a generated sound, in Hertz.
As the name of this class implies, the Bark scale is used by this class and is differing from the previously used Hertz scale. 
It represents frequencies in a manner that is closer to human perception.
It goes from the four formant representation in Hertz to a two formant representation in Bark consisting of the first formant and the \textit{effective second-formant} ($F'_2$).

We took the conversion formulae and calculation formula for the effective second formant straight from \citet{deBoer2000}.
The conversion from Hertz to Bark and back used by \citet{deBoer2000} is again interpolated from data and given in Equation \ref{eq:bark_conversion_de_boer}.
It is also admitted by \citet{deBoer2000} that his calculations for determining $F'_2$ are a bit ad hoc.
The used equations are given in Equation \ref{eq:f2_conversion_de_boer}.
The fourth case for determining $F'_2$ has been changed from \citet{deBoer2000} to reflect the effective equation used in the available code.
The critical distance ($c$) used for calculating $F'_2$ can be provided as an optional argument of the class instance but is set to 3.5 for all experiments.
Because of the interpolated conversion and ad hoc $F'_2$ calculations, we have also foreseen an \texttt{alternative\_bark\_conversion} parameter.
If set to \texttt{True}, the Bark operator will use alternative methods for both of these functions.
This is further discussed in chapter \ref{ch:improving_de_boer}.

\begin{equation}
  Bark =
    \begin{cases}
      \frac{ln(Hertz/271.32)}{0.1719} + 2 & Hz > 271.32\\
      \frac{Hertz - 51}{110}  & Hz \leq 271.32
    \end{cases} 
\label{eq:bark_conversion_de_boer}      
\end{equation}

\begin{equation}
  F'_2 =
    \begin{cases}
      F_2 & F_3 - F_2 > c \\
      \frac{(2-w_1) F_2 + w_1 F_3}{2} & F_3 - F_2 \leq c \text{ and } F_4 - F_2 > c \\
      \frac{w_2 F_2 + (2-w_2) F_3}{2} - 1 & F_4 - F_2 \leq c \text{ and } F_3 - F_2 < F_4 - F_3 \\
      \frac{(2-w_2) F_3 + w_2 F_4}{2} - 1 & F_4 - F_2 \leq c \text{ and } F_3 - F_2 \geq F_4 - F_3
    \end{cases} 
\label{eq:f2_conversion_de_boer}      
\end{equation}

Having our Bark space configured, we can implement a distance measure between utterances as specified in Equation \ref{eq:reimplementing_distance}.
This distance measure can be used as a way for the agent to determine the closest sound in his repertoire to the one it heard.
This must happen in the Bark space as equal distances in bark correspond to roughly equal human-perceptual distances of sound.
This is not the case for Hertz, as humans have a harder time differentiating higher frequencies.
With this human-like distance measure, agents can now perceive sounds and compare them with their known sounds.
This $\lambda$ is again an important parameter for the simulations.
It is set to $0.3$ for all experiments in the project unless specified differently.
This value is seen as realistic by \citet{Schwartz1997, deBoer2000, vallee1994, 1985book}.

\begin{equation}
D = \sqrt{ ( F^a_1 - F^b_1 ) ^2 + \lambda ( F'^a_2 - F'^b_2 )^2 }
\label{eq:reimplementing_distance}
\end{equation}

%------------------------------------
\section{Representing agents}
\label{sec:reimplementing_agents}

The \texttt{Agent} class makes use of all previously discussed classes as well as the \texttt{Sound} helper class.
The \texttt{Agent} class takes a synthesizer and Bark operator as arguments for initialising.
It also has over ten optional parameters one of which is a logging capability handy for debugging purposes.
The \texttt{Sound} class is used to store a known sound of an agent.
It consists of the phoneme, utterance, usage count and success count of the sound.
The utterance of this sound is determined by synthesising the provided phoneme in a noiseless environment.

To discuss the functions of an agent, it is easiest to present a typical imitation game flow.
Algorithm \ref{alg:say_something} shows the actions performed by a randomly picked agent who starts an imitation game.
If the agent known sound repertoire is empty a completely random vowel is inserted by picking random values between $0$ and $1$ for the Phoneme parameters.
A different randomly picked agent plays the role of imitator and responds to the heard utterance using the process shown in Algorithm \ref{alg:imitate_sound}.
If the imitator's known sounds repertoire is empty, it will add a \textit{similar sound} to the one it heard.
It does this by checking eight \textit{corner} sounds it can produce and pick the one which is closest in distance to the heard one.
Afterwards it improves this sound further by using its \texttt{improve\_sound} function for the agent specific amount of times (\texttt{max\_similar\_sound\_loops} parameter).
The \texttt{improve\_sound} function tries all possible permutation's of the phoneme parameters by either keeping the value or adding/substracting the agent specific step size (\texttt{phoneme\_step\_size} parameter).

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The say\_something function of an imitation game initiator agent}\label{alg:say_something}
\begin{algorithmic}
\If{No known sounds}
    \State Add random sound to known sounds
\EndIf

\State $S \gets$ random known sound
\State Update usage count of $S$
\State Remember chose of $S$
\State Return utterance of $S$ using own bark operator


\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The imitate\_sound function of an imitator}\label{alg:imitate_sound}
\begin{algorithmic}
\Require $U_{in}$: the heard utterance
\If{No known sounds}
    \State Add similar sound for $U_{in}$ to known sounds
\EndIf

\State Remember $U_{in}$
\State Find closest known sounds $S$ to $U_{in}$
\State Update usage count of $S$
\State Remember chose of $S$
\State Return utterance of $S$ using own bark operator


\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

In the second phase of the game, the initiator validates the imitation it hears in a non-verbal manner.
This process is shown in Algorithm \ref{alg:validate_imitation}.
The agent validates if the closest known sound to the heard imitation utterance is the sound he used to start the game.
He also communicates this to the imitating agent in a non-verbal manner.
He updates the success count accordingly and prepares himself for the next round.
The process of preparing for a new round is given in Algorithm \ref{alg:prepare_new}.
This consists of resetting the game variables such as the $last\_spoken\_sound$ variable.
The agent then updates its count of games played, together with the success and imitator/initiator count.
Based on the agent specific \texttt{cleanup\_prob}, \texttt{new\_sound\_prob} and \texttt{merge\_prob} the agent will potentially remove bad sounds, add a semi-random new sound or merge similar sounds.
A sound is thus removed periodically if its success rate is below the agent specific \texttt{sound\_threshold\_agent} and used at least \texttt{sound\_minimum\_tries}, which is also agent-specific.
A sound is also added semi-randomly periodically.
We call this process semi-random as multiple random vowels will be tried based on the agent specific \texttt{max\_semi\_random\_loop}, and the sound that had the greatest summed distance will be used as the new sound.
Finally, similar sounds are also merged periodically.
The agent does this by validating if both the utterance or phonemes don't lie too close.
Phonemes lie too close if their parameters differ less than 0.17 in total.
Utterances are too close if they can't be distinguished taking into account the noise of the environment.
Both of these calculations are taken from the code provided by \citet{deBoer2000}.


%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The validate\_imitation function of an initiator}\label{alg:validate_imitation}
\begin{algorithmic}
\Require $U_{in}$: the heard imitation utterance

\State Retrieve last spoken sound $S$
\State Find closest known sounds $S'$ to heard utterance
\State $success \gets$ $S = S'$ ?
\If{$success$}
    \State Update success count of $S$
\EndIf

\State Prepare for new game
\State Return $success$
\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------

\begin{algorithm}[hbt!]
\caption{The prepare\_for\_new\_game function of an agent}\label{alg:prepare_new}
\begin{algorithmic}
\Require $imitator$: whether or not the agent was an imitator in the played game
\Require $success$: whether or not the played game was a success

\State Update agent games count
\If{$success$}
    \State Update agent success count
\EndIf

\If{$imitator$}
    \State Update agent imitator count
\Else
    \State Update agent initiator count
\EndIf

\State Remove bad sounds per agent-specific odd
\State Merge similar sounds per agent-specific odd
\State Add semi-random sound per agent-specific odd

\State Reset game variables

\end{algorithmic}
\end{algorithm}

%-----------------------------------------------------
\newpage
To end a game cycle, the imitator agent will process the non-verbal imitation success communication.
It does this using the process described in Algorithm \ref{alg:non_verbal}.
If the imitation was successful the agent will use the previously described \texttt{improve\_sound} function once to make the spoken sound better match the heard utterance.
If the imitation was not successful and the used sound has a success ratio lower than the agent specific \texttt{sound\_threshold\_game}, the sound is also improved as described before.
However, if the success ratio of the sound is above this threshold it is assumed that the spoken sound is a correct imitation of other sounds in the network and thus a similar sound is added to the one heard as a reaction.
The process of adding this similar sound is identical as described when the sound repertoire of an imitator was empty.


\begin{algorithm}[hbt!]
\caption{The process\_non\_verbal\_imitation\_confirmation function of an imitator}\label{alg:non_verbal}
\begin{algorithmic}
\Require $success$: whether or not the imitation was a success


\State Update agent games count
\If{$success$}
    \State Update agent success count
    \State Improve used sound to better match the heard utterance
\ElsIf{Low success ratio of spoken sound}
    \State Improve used sound to better match the heard utterance
\Else
    \State Add a similar sound to the heard utterance
\EndIf

\State Remove bad sounds per agent-specific odd
\State Merge similar sounds per agent-specific odd
\State Add semi-random sound per agent-specific odd

\State Reset game variables

\end{algorithmic}
\end{algorithm}

%------------------------------------
\section{Playing and analysing games}
\label{sec:reimplementing_game_engine}

To play the imitation game for a specified amount of iterations and to store the results, two additional classes were made.
The \texttt{GameState} class stores a copy of the agents at a certain point and the iteration number at which the copy was made.
It also has a plot function to plot the sound repertoires of agents, grouped per agent.
The \texttt{GameEngine} contains a simple loop to play imitation games for a specified amount of iterations.
The \texttt{play\_imitation\_game} function returns a list of \texttt{GameState} objects at the specified \texttt{checkpoints} (iteration numbers) by playing the imitation games.

To make evaluating the obtained \texttt{GameState} objects, and thus experiment results, easier, a \texttt{Statistics} class is created.
It allows for easy calculation of the average and standard deviation for \textit{energy}, sound repertoire \textit{size}, and \textit{success rates} of agents.
These results can also easily be plotted by the provided functions.
To compare the emerged sound systems with real human vowel systems, a function \texttt{plot\_known\_vowels\_over\_sounds} is provided.
This plots the known vowels used to derive the interpolated synthesizer function on top of a plot from the agents' vowel repertoires.

The data and plots obtainable from these classes are used in chapter \ref{ch:results} to discuss the results.